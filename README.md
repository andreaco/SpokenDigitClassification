# Spoken Digit Classification
- **Description**  
Implement a classifier able to predict which digit is pronounced in a short audio excerpt.
- **Input**  
The dataset used is the [Free Spoken Digit Dataset](https://github.com/Jakobovski/free-spoken-digit-dataset) (FSDD).

In the folder recodings you will find the audio files named in a specific format. Please read the READ ME distributed with the dataset. The results of the classification must be reported as a confusion matrix and, optionally, other metrics of your choice.
- **Output**
  - a brief presentation of your work (max 5 minutes) that will be given to the class
  - a more detailed report in which you illustrate and explain every step of your
classification system and in which the results are shown and commented (max 8
pages) to be delivered by May 17th.
  - a link to a repository containing the code (e.g. on GitHub) with minimal comments.


### Tasks:
- [x] Preprocessing
- [x] Feature selection
- [x] Dataset split
- [x] Feature extraction
- [x] Feature selection
- [x] Classification
- [x] Performance evaluation

## Features
[Mel-frequency cepstrum coefficients](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum)  
[Linear Predictive Coding](https://en.wikipedia.org/wiki/Linear_predictive_coding])  
[Phoneme detection](https://dataprivacylab.org/projects/bebe/paper.pdf)  
[HiddenMarkovModels](https://en.wikipedia.org/wiki/Hidden_Markov_model)  
[Image processing on spectrogram](https://www.isca-speech.org/archive/archive_papers/interspeech_2014/i14_2533.pdf)  
